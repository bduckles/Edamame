¥éËSupposeStory1,SupposeStory2,,Suggestions,same as pre-survey,same as pre-survey,Same as pre,"I like the Stuart's approach. Start with intro, let us work on our data and then come back for summary/lecture. Allowing time for students to work through tutorials themselves would aide learning. ",I think my answer is more or less the same as the original one at the beginning of the workshop. The main challenge in working with non-model systems are the limitation of databases to assign reads.,NA,Same as pre,"Workshop is perfect to avoid ""the hard way"" to learn bioinformatic analyses without a computing background (most of us I think). Lot of tips and useful information/criteria to analyze the data. Getting the right criteria is probably the most important thing.",Hard way NA,NA,No answer,Thank you all! Thank you Taylor for amazing organizing! Thanks to our TAs! Thanks for the USDA and NIH for funding!!!! ,TYNA,NA,No answer,"The only comment I would recommend is to add one more day. After all the workshops, it would have been nice to have one day where we sit in the classroom and have the instructors and TA's walk around while we have dedicated time to work on our own projects. That way, if we hit a snag or have questions we can get advice from the many experts in the room. I know the goal this year was to make the workshop shorter (from 10 days to current) but I believe one more day to apply the knowledge we learned to our individual projects would be powerful. Perhaps come in on a Saturday (instead of a Sunday) and leave on a Saturday (which would allow that one more day).",Add day"challenges: getting quality data , install mothur and get additional resources to help with the data after sequencing.Install the right packages and R for the graphs. make sure the reads are good making sure the data makes sense at every step of manipulation ","Approaches: assembled analysis or unassembled analysis or even based on target genelimitations: In assembled analysis, need to go through additional steps",Answer,"Great work by Adina! and the volunteers! This was a great opportunity to learn since I will need this for my research. I would also like to thank USDA for providing funding for room and board. A quick thanks to all the guest speakers A thank you to NIH for organizing this. This is certainly a workshop I would recommend to my colleagues. ",TY"Using mothur: assemble and trim contigs. Trim ends. Remove chimeras. Group contigs. Import a reference database . Compare contig sequences to database sequences and assign OTUs. Compare non-model microbial community to model community.  Challenges include: working with a large data set, rarefying samples if uneven sampling occurred. ","After assigning OTUs for each sample site I would rarefy to the lowest abundance sample. Then use bray-curtis distances and probably an NMDS plot to visualize the differences between the two communities. I would do a permanova to statistically prove any significant difference between the two groups. Technical limitations include access to a ""good"" database and number and quality of the reads. ",Answer,"It would have been nice to do some work with qiime so we could maybe have a better personal understanding of both systems, but I understand the time constraint. I would also have liked to have a little more time to work individually with our own data. A phyloseq/vegan tutorial or overview might be nice in the future. I really liked hearing about the different work that the speakers were working on and having down-time to discuss our own research/problems between ourselves. The TA's were great! Thanks USDA/NIH. I would do this again or recommend it to others. I think the resources we now have will make future analyses much more streamlined and efficient. ",Time constraint"I would use mothur to analyze the 16S rRNA gene markers from the non-model worm, but now I would know to use a de novo method for OTU assignment because it is unlikely these unique bacteria would be found in reference databases. I still see mitochondrial DNA being a challenge in this study, but I know now that mothur has a command for removing eukaryotic DNA that could help resolve this issue. ","To analyze the data I would use a similar approach to above (i.e. use mothur), but I would potentially use a soil database and assign OTUs based on reference genomes instead of de novo. I would cut off the specificity at 97%, but I would be careful not to call these bacterial species! This method limits the amount of functional data that can be obtained from the sequences, but you could still use the 16s data to determine the structure of the communities because the samples are evenly distributed. ",Answer,"My biggest fear in trying to repeat these steps on my own is that I will not know which part of the code to alter for my sequences in terms of file names (not parameters, as this was well covered). Therefore, it would be great if file names were highlighted in a different color in the code so it is easier to change what needs to be changed when we have to repeat the steps on our own. This might be impossible, but just a thought!",Suggest"I would need to trim and clean up the read data (search for chimeras, primer ends) and then rarefy to adjust for sampling effort. It is likely that the organisms present in the unique digestive tract are not in current databases and, thus, it would be important to cluster our otu's with a denovo approach. If there is relatively low microbial biomass in the worms, it would also be good to have a control sample to isolate any DNA that is added due to extraction procedures that could, in turn, make the two worms seem more similar than they are. After de novo OTU clustering, we could use an external database (like NCBI) to group our reads by phylogeny. I would primarily use Mothur and R to analyze these data. ","In order to compare the metagenomes of these two soil types, it would first be important to make sure that there are quality reads in the metagenomes and sort the paired and unpaired sequence reads. If we wanted to have the most data to generate genome profiles, we could put the two soil treatments into the same dataset before running through our pipeline. With the metagenome data, we are able to identify differences in the microbial taxonomy between the two sites as well as the presence of functional genes in the two sites. However, it's important to keep in mind that the presence of the genes doesn't not mean that they are being up-regulated or functionally active. ",Answer,"Thank you for the great workshop! I'm really looking forward to use these resources to analyze my microbial dataset and to better understand which analyses and options I should use in testing and presenting my data. The plenary speakers were inspiring and provided relevant information on the current status and future for microbial ecology. I think it could have been helpful to have the Mothur workshop earlier in the week so that we could process our amplicon data and get help during ""open-hours."" Also, I think that having Saturday extended to have ""open hours"" (or another day?) would be a great way for people to try out the new methods we learned in a helpful environment! :) Thanks to the USDA and NIH for making this program possible! (and of course all the instructors and TAs!)","TY, Time ""Using Illumina MiSeq, sequence at 250 bp depth multiple samples from multiple individual worm guts. A challenge is that this community is unique and probably isn't well represented in databases for reference communities. You will need additional databases to reference the OTUs to. There will also be challenges in the accuracy of the sequencing, which will need to be solved during quality control.","Bin the sequences into contigs and determine if there is a statistical difference in the contigs represented at each plot type using analysis such as ANOSIM or PERMANOVA. This will not be as sensitive to functional specificity, but will show taxonomic differences. A technical limitation is that there is only one farm, so this study cannot be extrapolated to other farms that have corn or dairy pastures. Another strategy could be finding sequences of a specific gene type, such as nitrogen fixation genes. Then, one can determine the diversity of nitrogen fixation genes found in each site to determine the functional diversity of the area. These can also be used to determine taxonomic diversity. This is an easier analysis, because it does not use all of the genetic information, which requires a lot of computational space. But, it also gets rid of potentially important information.",Answer,"It would be useful to structure the tutorials in a way that doesn't involve copy and paste. For example, put the source code for what needs to be run without the specific file names and parameters, so that we have to determine the best way to use that code. Then, put the answer at the bottom of the screen, to check if we are right or find the solution if we're lost. This is more like what we have to do when we search for new code and programs online, and it will allow for more critical thinking during the tutorials, which can get long if one already has a background in using the programs. I also would have liked a bit more instruction using QIIME, so that I can compare the workflow of the two programs. ",Suggest"Same response as before, except I didn't think to mention the first time around: what is the question we're even asking here? Just ""I want to know what the community is like"" is not a valid question, so I would add that a ""challenge"" might also be somehow justifying sequencing for no reason whatsoever without having a question in mind for which sequencing is appropriate.","Also same response as before; i.e., issues with ""cow"" microbes vs. just soil ones and whether we want those included, etc. I don't feel that this course particularly shifted my opinion on either of these two answers.",Same as pre,"This course definitely met/exceeded my expectations. My lab group uses amplicon sequencing pretty much exclusively, so I was hoping to at least get an idea of how shotgun sequencing analysis was approached and used (check!) as well as review of using R for analysis (check!)---aside from a hurried vegan tutorial over a year ago, I've not had much practice doing this and have been (embarrassingly) relying on Primer as a crutch for data visualization. Additionally, practice using the shell outside of the usual workflow we use in our lab was useful for me, as well as exposure to using mothur and being able to compare and contrast this to usearch + QIIME (which we primarily use in my lab).No one else in my immediate or collaborating lab groups has attended this workshop before, so I volunteered to come here on more or less a ""scouting"" basis to see if it would be a useful workshop to send other lab members to in the future. I definitely will be recommending it to others both within and outside of my lab group, because the breadth of topics and methods covered was impressive for a 5-day course, and the ability of the instructors and TAs to make things run so smoothly with such a diverse group of backgrounds and experience was impressive. That you are also able to offer a measure of financial support to cover the cost of room and board makes attending the workshop realistic for those who may not otherwise have been able to attend (myself included), and whom may not have otherwise had access to this type of guidance at their own institution. I definitely hope you guys continue to run this workshop for years to come, because it really represents a valuable asset to any field benefiting from the methodologies and philosophies of microbial ecology.",TY"Amplicon sequencing of the 16S rRNA gene, errors: sampling, sequencing, analysis based - dealing with unknowns, not having high resolution for lower taxonomic groups, not having functional data to link structure and function, statistical power for determining interactions/co-occurence","I would use shotgun metagenomics to sequence this data. This allows for the taxonomic and functional sequence identification required for completion. Technical limitations will be sampling, sequencing and analysis based like beforeSampling - could generate more data than what is required to answer the question, there is no controlSequencing - check for sequence errors, are mock communities requiredAnalysis - picking between assembled and unassembled metagenomic pipelines",Answer,"I liked the intimacy of the course, i got to have at least one conversation with every student hereI thought the workshop could have been designed in a step-wise manner - from shell - sequence analysis - statistical analysisI would have open lab days dispersed throughout the course if you want to keep it at 7 days - 2-3 times during the week during evening sessions and not solely at the beginning of the course or have all day the last day be an open labI would kick the workshop off with the keynote highlighting bioinformatic tools taught in the course to really drive home the applications of what we are doing hereI didn't understand the point of having guest lectures. Took up time better spent working on our data and making sure we leave here knowing how to install&use it on our own computers outside of AWS",TY suggest"decide on the type of downstream analyses and hypothesis testing to be run r to answer biological question of interest. Assemble and align contigs from sequence reads,   check quality of assembly and remove low quality reads,  (all reads were fully overlapped), trim contigs, assign reads and check for chimeras, remove mock community if used, generate count table and taxa table if appropriate, carry out down stream statistical analyses on community (visula exploration and hypothesis testing. ",NA,Answer,"consider not holding workshop as the same week as ESA.  If possible, consider an extra day to the workshop but without adding more material in order to make time for more open office hours or open work hours to explore what we learn on our own data while the experts are available",Suggest"I would choose a primer set for 16S that gives me good overlap (~250-300bp product) when using the MiSeq Illumina platform with 2*250 bp reads. I would sample from a large number of worm guts and perform sequencing, then use MOTHUR to perform ""data hygiene"", map to a 16s database, and create count tables for downstream analysis in R. I expect that this unique digestive tract will contain many poorly characterized OTUs, so I would try to mine public data sets  for other worm gut microbiomes and use multiple 16s databases (GreenGenes, RDP, Silva) to try to better characterize the community. ","First, I would pool the (trimmed) reads from all the samples and do a metagenome assembly. Then I would search for different functional genes of interest (nutrient cycling, etc) by first downloading known sequences of those genes from the NCBI site and doing a local BLAST to count them in the samples. I would also identify 16S sequences from the metagenomes in order to do taxonomic identification. Then I would use those count tables to perform similarity/dissimilarity correlations in R to determine differences between the two types of plots. I expect that in soils (unless I do very deep sequencing) I would have low sensitivity for identifying functional genes and taxonomy. One technical limitation of the analysis using an assembled metagenome is that much of the data will be effectively thrown out if it doesn't assemble into larger contigs. One way around this is to do an unassembled analysis. ",Answer,"Thanks for everything - I learned a lot. And thank you to the USDA and NIH for funding this workshop and my attendance!I would have liked a bit more introduction to computing language; commands were very well explained, but I'm still not sure what the differences between terminal, the shell, and bash are. I also appreciated the data visualization workshop in R, but it would be nice to include visualization of data more relevant to metagenomics (staked bar charts, etc.) I appreciated all the insight, details, tips and tricks from the instructors on the different programs and methods for assembly - much more helpful than just going through a tutorial on my own!The TAs were excellent and incredibly helpful. Thank you!",TY "Based on Pat's advice, I'd focus primers on the V4 region. I would then take my data and run it through the mothur pipeline we went over on Friday to clean up overhang, chimeras, etc. At some point I may have to throw out samples with small amounts of data, and set an appropriate level of sequences for subsampling (the smallest sample, or a cutoff near the small end). If I have a lot of samples, I'll need to set all this up on a cloud computer to run it, make sure I have a tmux or other program running to keep me connected, and pay for enough time at the outset of the analysis. The output should be an OTU table, which I would then export, probably using FileZilla, and bring into R. In R I can make distance matrices (probably weighted, to account for relative abundance), do multivariate ordination (probably pcoa, in order to report axes % importance), and pick out OTUs most responsible for differences among worms. Since the sequencing is on 16s and primer-based, we will only see a subset of all DNA, but it may reveal phyla responsible for the specialized diet.","This kind of sequencing can be seen as an exploratory tool to ask the question, how are soil microbial communities different under the two treatments? If based on the metagenomes some functional genes differ strongly, we could do a follow-up looking at those genes in particular, or run a BLAST to pick out just abundances of those genes within the metagenome. There may be a tradeoff between sensitivity and specificity. For the question of what is different on a community level, specificity may not be very important. But if you move into evaluating the variations in a specific gene or group of genes, you may adjust your ID cutoff to be more specific and less sensitive. Keep in mind that assembly of OTUs is a) based on the sequences you have, which may not be as long or useful for assembly as you would like and b) based on the available databases, which are less  complete for soil than other habitats. So while you may pick up relative differences between samples, it may not be appropriate to state the an absolute effect of environment on a given OTU. As with 16s data, the eventual output would be an OTU table to be analyzed in R using ordination and probably permanova to detect differences between groups. Cloud computing would certainly be necessary to assemble genomes. ",Answer,"A timekeeper should have been tracking the last two days of work better, so that breaks weren't eliminated. It was too much to not have any time to ourselves on those days. Also, while the research talks were all interesting and well done, they were hard to pay attention to at the end of the day, and were not the main reason I came.It would be great to have a half day devoted to running your own data through whatever pipeline you need to.... realizing that the time is already pretty full, I agree that this is the part to cut, but it's a big jump to move from model data to your data.I really appreciate the willingness of TAs to dive into individual questions!The whole workshop vastly increased my confidence in talking about and analyzing genomic data.",Time I think it would be critical to do a pilot study prior to doing my full experiment. The reason being is because I'm assuming that there is a low likelihood of matching my 16s sequences to any reference databases. Part of this pilot study should include some culture based techniques that will give me the option of curating my own reference database in addition to the resources already available. ,"Sequencing depth is critical when designing these metagenomic experiments. I would perform a pilot experiment to target what I think is an optimal sequencing depth. Once the sequencing data is collected, I'd have two general options for analyzing this data. I can take an assembly based approach where I immediately assemble the metagenomic data into contigs and compare differences in the community as a whole or I could use a gene-based approach where I attempt to align my sequences to genes of interest, like nif-genes, to see differences in genes related to nitrogen fixation. Using the later, gene-based approach will likely give me more hits and allow me to use more of my data, but it is limited in scope because it is gene focused meaning I'd have to be interested in questions about specific genes. Additionally, I have to acknowledge that this approach is only as good as the databases that contain the gene identification information. While the full metagenomic approach would give me information about patterns in community composition, it is notoriously difficult to assemble de novo metagenomes without good references. This means that I will likely throw out a lot of my reads and not have the same sensitivity as if I used the gene alignment technique.  ",Answer,"I was very impressed with how all of the courses were taught. There are definitely topics that I wish were covered such as experimental design and more complex methods of data visualization, but I think you guys did a good job selecting the best ones. I had a fantastic experience and will recommend it to anyone planning on doing some sort of metagenomic analysis of their study system. ",TY"Amplicon sequencing utilizing targeted assembly directed at the genes related to the unique digestive tract. Also comparing the 16S amplicon sequences to the NCBI database (or other similar resources) of the organisms to determine community composition and potentially significant organisms. Challenges may include reference information (lack of or incorrect), not knowing the actual genes present and only who is present, quality of sequences,  the distribution of data, biases","You could look at the presence/absence of OTUs, the relative abundance of OTUs. Technical limitations may include identifying, clustering and classifying OTU's. Other technical limitations may include the fact of DNA samples and that it would not necessarily show actual function. Also, normalizing both datasets.",Answer,"Either another day or just some dedicated specific time to really focus on applying the skills learned to individual datasets. Perhaps having some of the speakers talks earlier in the day and finishing with tutorials or mixing it up between days (starting with talk then tutorials, starting with tutorials and evening talk). Also plan for realistic and needed breaks to increase productivity and what will be obtained from course.I commend the instructors/workshop on having speakers with research/projects showing course aspects applied to relevant research and topics. Loved the atmosphere and mentality of instructors as they came across as non judgmental in all regards to all skill levels. Great course! Really appreciated the content of the course, the people, and the aid from USDA for room and board! ",More time "In the amplicon analysis I would probably be most interested in the OTU binning as opposed to phylotype or phylogenetically in order to get the best idea of total diversity and changes with treatment of over time. Challenges would be to reduce contamination, and then databases would probably not have a lot of the information I need since this is not a model system. I would have to try to critically evaluate the database info. Additional resources needed would be R packages to run the abundance statistics. Meta-data will also be useful depending on the experimental design.",I would do meta genome assembled analysis and map raw reads against the reference genomes. I would expect this data to be sensitive to sequencing depth so I would need to evaluate the sequencing depth and determine a good cut-off to standardize the samples. I would also expect this analysis to be sensitive to rare sequences and therefore would analyze the relative abundance as opposed to presence/absence. ,Answer,"I thought the local BLAST information was very good, but for me, it did not have a context so I am still a little shaky about how to use that/when to use it/ what it is useful for. However, I am sure as I proceed in my research, the time will come that I run into an issue and some where in the back of my head I think I might know a tool that will help with that issue and in my notes I will find the local blast instructions and it will suddenly make sense. I came into this most hoping to get comfortable with Mothur. Unfortunately, Mothur is what I am leaving here being still the most uncomfortable with. I thought the tutorial was helpful and will certainly be helpful in the future. I think information we received from Pat throughout was also extremely helpful, but maybe we went too fast or I did not have a sound enough background of the overall process to put the steps into context. I found the ""Chalk-talks"" about the meta genome analysis largely relieved the anxieties I was having about meta genome analysis and the tutorials, so maybe I needed a broad conceptual overview of the amplicon workflow as well. It did not seem there was time and I know we put a lot of stuff into a short period of time, so no complaints. I thought overall, the flow and atmosphere of this workshop was extraordinary. It was a great learning environment and I felt comfortable asking for help and receiving help. Thank you all so much. Thanks also to the USDA and NIH for supporting this program. It was a lot of informational bang(!) for the buck. I am so grateful to have been accepted to come.",Suggest"Besides the need of a control to compare data, I would use Illumina's platform to sequence the data, the challenges that I expect to find are analyzing the data, but mostly in the ecological and statistical analysis. Understanding how the statistic software (R) works is still an issue for me, and understanding all the ecologic data and options to represent it is another, so I need to dig into it, and understand what I'm doing before actually doing it.","One approach is assembling the metagenomes into contigs, the other is a targeted gene assembly if you are looking for a specific kind of genes. The taxonomic and functional sequence identification depends on the quality of your data, the size of the contigs and how much information do they give. I think that usually with total DNA sequences there's a good chance to give a taxonomic assignation to a genera level of the most abundant community, and depending on the genes present in the contig if you could have the functions.The limitations of the analysis are that Illumina's reads are too short and sometimes assemblies are difficult, so you could have different contigs for a single genome and considering like different OTU's. The other issue is the annotation of the genes, cause free databases (MGRAST) takes too long to analyze.",Answer,"It was a wonderful course. It was completely different from what I expected, but that was because I had no idea of the aspects involved in metagenomic analysis at all. I'm glad that you covered everything at a basic level, cause now I just can get home and I know how to get started, which is usually the hardest part. So I'm really grateful. I also really appreciate the financial support of the USDA, it made so much easier for me to come to the course.",TY "Using V4 region, we could look at the phylogeny of the microbial community in the gut. Since the V4 region is only ~250 bp we can use illumina for this. We might also consider the merits of using a sampling method that would give longer reads (PacBio) and span a longer region since we don¾ét necessarily know what the community will look like and we might want the longer reads to get a better idea of phylogeny (?).","We can get overall, broad characteristics of taxonomy and function by blasting raw reads or assembling in to contigs then blasting. If we have questions pertaining to specific functions we might consider using the contigs for a functional gene based assembly. This is good if we are looking for specific functions and/or under represented functional genes. We might also construct a reference assembly from all of our contigs to then map back to for a more complete view of what functions are attributed to each OTU (MAGS approach), using this approach we also get information about the gene neighbors.",Answer,"This workshop far exceeded hopes and expectations. Anything that was rated as ""good"" rather than ""very good"" was only because we could have used more time.FDA / NIH feedback: This workshop has provided the tools that I needed to get through the next steps of my PhD project. I have actively looked to acquire these skills  through the classes taught at my university,  but EDAMAME workshop has taught me more in a shorter amount of time and I now have the confidence and community to complete my work.","TY, more time""take samples from worm gut -> extract DNA -> 16S sequencing -> trim -> assembly -> mapping -> generate clusters to identify similarities of sequencing products The qualities of sequencing data could be a challenge. To analyze mapped data, the control could be a problem to set up.",I could analyze the data with MOTHUR from 16S sequencing or with assembly-based analysis from metagenome sequencing.,Answer,"Maybe you can share some basic information earlier before the class begin, to give someone like me have some time to warm up to the intense lectures.",basic suggest"I would begin by extracting DNA using a fecal DNA kit and submit for 16S sequencing through an Illumnia Mi-Seq run to get a general idea for the composition of the gut biota.  Since I don't know what's in there and there is a chance that there may not be good references for these potentially unknown organisms, I would use de novo clustering of OTUs.  I would then compare the final OTUs to the NCBI database to identify which taxa are present and compare this with other relatives of the worm (potentially congenerics) by plotting them in an PCoA and comparing differences in the community.Since I'm interested in how the worm breaks down a specialized diet, I would eventually use a shotgun sequencing approach (assuming I can afford it) because that way I would get an idea for the potential enzymes that the gut microbes may be producing in the gut.  Perhaps there would be specific enzymes that are unique to the substrates in the worms' diet.  I would only do this after I had already done 16S sequencing from the samples because I would want to first use that cheaper approach to look at the community makeup.","Once I got the sequences back and I had removed the adapters and quality controlled the reads, I would normalize the total number of reads per sample to the sample that had the lowest number of reads (assuming it had at least 2000-3000 reads as a minimum).  I would then compare the composition of the sites using a PCoA that incorporated environmental metadata to see what other covariates were also different between the two plot types (like soil chemistry measurements).",Answer,"Coming in to the course, I still struggled a bit to understand how some of the actual sequencing technologies worked and this made it difficult to understand some aspects of the analysis pipeline (like what's going on with adapters in Mi-Seq).  Perhaps an early introduction to how these sequencers actually work early on in the course would be helpful.",suggest"Determine which primers were used to create the model worm gut library and use those for comparing to the model group, and use v4 to create our own reference library, V4 primers can be used for comparison to other environments. I would create bray curtis matrices and analyze them with anosim. I would determine the alpha diversity of the specialized worms, and then the beta diversity by comparing the special worms to general model worms. I would like to look at different life stages of the worm and compare the microbiome at those time points. It also be interesting to explore the microbiome of the specialized food source to help determine how much of the bacterial populations originated from the food source. I would also try to feed the worms a similar, but different diet to observed shifts of the microbiome. ","I would approach this with an assembled based approached for the different types of soil. For both environments, I would follow this protocol: Raw read -> Trim -> Assembly -> mapping -> Table, where the table would have the list of functional genes. I would use bray curtis to create distance matrices and then compare the structure with anosim. I would BEST analysis to determine which genes contributed the most to the individual plots and globally. Then the function of those genes would be determined, and I would compare the gain or loss of function between the two environments.",Answer,Workshops were great. It would be nice to have a discussion about challenges and needs facing all microbial ecologists to use our specialized datasets to answer larger questions.,suggest"We discussed the technical challenges associated with steps upstream the sequencing strategy, such as sampling strategy, DNA extraction protocol, primer design/use, library prep chemistry, etc. that can affect the quality of our data. Considering these resolved, a good sequencing strategy could entail sending replicates of samples across treatment and a mock community (to assess data quality) to the sequencing center. To process 16S rRNA raw sequencing data we first need to have the computational resources required to carry out computational intensive calculations, which generally mean having access to an institutional server. However, this week we've learned about cloud services that can help us overcome this, if it is not readily available for us or if it's a financial limitation. Next we need to have the required software and dependencies installed in our image computer. Then we  have to organize our data, so that we follow the guidelines for data hygiene observed in the course. We've learn that there are multiple pipelines developed for 16S rRNA data processing, and in particular discussed MOTHUR. After making conscientious choices about the parameters, we generate Meta table, OTU table, and a Taxa table. After this, we are ready to statistically test our hypothesis and generate plots. This can be performed using R. Some analyses that can be used to test the effect of diet, could be looking at between sample diversity (Beta diversity) analyses based on treatment type, AMOVA, among others.","For this type of data, the same upstream concerns as for the previous example apply except for the primer bias if we take a shotgun metagenomic approach for sequencing. The workflow required to analyze the raw data could consists of a denovo assembly approach as follows: 1. trim reads for data quality, 2. generate reference free contig assemblies, 3. map reads back to contigs. Afterwards we can generate read count tables and perform the same downstream steps as for the previous examples. ",Answer,"Thanks to the EDAMAME instructors and organizers for providing an inclusive safe learning environment and being not only talented scientist, but also lovely people. Thanks to the sponsors for making the workshop possible and providing us with a comfortable lodging experience, which made the process so much better. For following years I would suggest to add a day to review the statistical aspects and guiding more towards which test are relevant to test our hypothesis more in depth. ","ty, more time "Because this is a non-model worm and unique there maybe many unclassified taxa in the gut of the worm. Since 16S data only gives you who and how many are there you may not good a good sense of the specific taxa in the community but you could get a sense of how diverse the community is. I think in this case a metagenomic study combined with 16S would give you more information in characterizing this gut community and would allow you to make hypothesis that could be answered with 16S data. ,I think by total DNA from soils this is referring to metagenomic sequences. If  it is metagenomic data the sequencing will not be as deep because there is so much diversity in a soil sample. You could probe the reads and unassembled sequences for functional genes by using known functional genes sequences found in the FUN database. I think with this type of data it is harder to see who is there and could also be combined with 16S to get more who is there community information. I probably did not answer these questions very well but many of the tools and concepts I learned this week are still very new to me and this is my first go at thinking about this type of data. However I feel after reviewing the materials and exploring my data some I will have a better handle on this. ,Answer,Everyone was super awesome and nice and very knowledgeable. It was really nice to be in an environment where people were kind and happy to help me and I wasn't the only one interested in microbial ecology. It is very clear that the TAs and instructors have expertise in sequence analysis. Thank you for your time and willingness to share. ,"ty people, ""I would want to generate paired end sequences of the V4 region using a large number of worm guts to capture a great deal of variation in the communities. This will come at the cost of sequencing depth, but I imagine it should be fine as I doubt the community is too crazy complex given the niche diet.  I liked Patrick's technique of attaching indexes and adapters in one PCR run to limit chimeras.16S data could then be worked up in mothur. One issue is that our weird worm gut microbes might not be in any reference databases, but with a short region like the V4 de novo assembly will be fine.  I would also have one of my hypothetical minions work on trying to isolate some gut microbes for sequencing of pure cultures to use as references in future assemblies and sequencing projects on the worm microbiome looking at different, larger genes.","Data from all samples are to be included when assembling the metagenome which will serve as a reference for future analysis. We'll then index and map reads to this reference. We'll probably want to target functional genes depending on what our problem is (maybe nitrogen use?). Taxonomy as always will be very difficult given the lack of great databases for soil In either case, since they're very complex coverage won't be super deep.  Technical issues will include huge computation costs.",Answer,"Everyone did such a great job. I'm super impressed. Thanks to the granting agencies (USDA and NIH) that helped with funding, I'm sure it went long way in keeping things moving smoothly. The only change I could think to make would be to increase the length a bit (1 or 2 days) but not increase content. Instead, add more time to work on your own data under instructor supervision.",more time"I am unsure of the question that is being asked with this dataset. To explore the composition and diversity of the worm gut microbial community? To compare the worm gut microbial community to  the microbial community of its nearest relative (who may not have a unique digestive tract)? To see which bacterial groups are enriched in the gut of this worm that are perhaps responsible for the the breakdown of the specialized diet? The question will drive the sequencing strategy. I would obtain as many gut tissue samples as I can (100+), ensure that the worms are similar in all regards (weight, diet, environment), do Illumina 16S rRNA sequencing of the V4 region. If I had the money, I would actual do shotgun metagenomics because this will be more informative than amplicon sequencing if we are more interested in the function of the gut community. Resources I would need: EC2/hpcc server, mothur, R, metabat (and the other metagenome software we learned about), metadata.","I would send at least 10 soil samples from the corn field and 10 from the dairy cow pasture for shotgun metagenomics. There are 4 ways you can analyze the metagenomic data: unassembled analysis where you blast your reads against reference database in NCBI, assemble your reads into contigs, zero in a particular genes of interest (targeted assembly) and get counts of your genes of interest, or metagenome assembled genomes where you separate your contigs into bins and then map your sequences to these assembled genomes? Each approach has its limitation (some give you more specificity, some more context of the genome organization, or degree of horizontal gene transfer). BUt all of these methods are limited by the reference database that exists and how much the ecosystem has been studied. I learned that in soil, there are still lots of uncultured and unclassified bacteria and unknown genomes, and only a percent of the sequences will be assembled.",Answer,"Perhaps center the workshop around a case study; if there is an interesting question we can ask with data that is available, let's use that throughout the workshop. Analyze those 16S rRNA sequences in mothur, use that resulting OTU table to analyze and visualize data in R (alpha diversity scatterplots and wilcoxon tests, pcoa, permanova, mantel test), and if we have accompanying shotgun metagenomic data, also use a portion to run through the metagenome assembly tutorial. Just try to have this single question we are exploring throughout the workshop but using different tools. I am a visual learner and it would have been helpful to learn more about the structure of data, especially metagenome data, i would like to know what the reads look like before being assembled, after assembly, what does an assembled genome look like, the bins and everything I have never worked with or seen metagenome data before, so it is still very abstract to me. The workshop was fantastic, I have learned so much, and will go back and show all of this to my lab. The tutorials were  detailed, organized, and easy to follow. Thank you to all of the instructors/professors/PIs, TAs, NIH, USDA, and classmates for making this experience possible. THANK YOU!",suggest