ID,Suppose16S_Post,SupposeSoil_Post,16S_Vignette_Post,Soil_Vignette_Post,OVERALL WORKSHOP RATING,OVERALL INVITED SPEAKER RATING,,Did you take this workshop remotely at Notre Dame?,How well did this workshop meet your needs?,Did you learn what you had hoped to learn from participating in this workshop?,Did your understanding of computational science change because of your participation in this workshop?,Would you recommend this workshop to your colleagues? ,Did you participate in EDAMAME remotely (e.g. teleconference)?,Please provide any comments or suggestions to the instructors for the improving the workshop. We value your feedback.,CommentCode1,CommentCode2,1,"First I would need to determine how many individuals to sample, and how many reads I would need per sample to get the coverage I needed to answer my research questions, using a MiSeq run. I would first look at similar studies to see if I could find a rarefaction curve for this or a similar taxon. Since this is a non-model organism, it might be the first study of gut microbial communities for this species, and I would probably be more interested in the abundant taxa than the rare taxa, which would mean fewer reads per sample. After sequencing, I would check the quality of the sequences, and then use the mothur SOP to trim, define OTUs, and assign taxonomy. Deciding on how to define the OTUs would be one of the challenges. Then I would analyze alpha diversity and beta diversity and whatever other analyses were specific to my research question.","Two possible approaches: assembly-based analysis, or read-based/mapping methods. I'll be honest - I didn't pay quite as much attention to the metagenome analysis section of the workshop because I am working on amplicon analyses. But I know that I would first use digital normalization so that the samples were sequenced evenly. And then I would use Megahit to assemble the contigs, and metaBAT to bin them into taxa.  ",Answer,Answer,Very Good,Very Good,,No,Very Well,Yes,Yes,Yes,No,THIS WAS GREAT,Positive,,2,,,NoAnswer,NoAnswer,Very Good,Very Good,,No,Very Well,Yes,Yes,Yes,No,"All the aspects are very well.TAs were very helpful in all informal settings (answering questions, approaching the red flags, general logistics), but teaching could be a lit bit more formal to ensure everyone is one board and tagging alone.PIs have been very generous and supportive of the class, including intervention to clarify concepts.great job!!! thanks!!! ",Positive,TA,3,,,NoAnswer,NoAnswer,Very Good,Very Good,,No,Very Well,Yes,Yes,Yes,No,"The workshop is very comprehensive and we covered ALOT of very useful and great material. I was pretty much at zero with a lot of it prior to coming. More time to go through what we did each day, and apply it to our own data would have been useful, as this is when you really learn. I really enjoyed the guest speakers, but perhaps moving these to 5.00 and then having the evenings to try out data sets? or alternatively reducing the numbers of guest speakers..they were great but  something would have to be reduced to fit in more time getting familiar with what we were taught.",Positive,Beginner,Speakers4,"Select gene target (preferably V4) and platform (Illumina MiSeq), include mock community and standard controlMake a workflow (trimming, form contigs, align contigs, make OTU table, assign taxonomy, use either mothur or Qiime)Extra Information: Host DNA sequences to remove after sequencingChallenges: How deep to sequence (how diverse is the gut microbial community?)","Trim reads (Trimmomatic), assemble contigs, bin contigs, assign taxonomy or ID target genes (MG-Rast or Xander).Quality of data coming out is limited by DNA quality and sequencing quality going in.",Answer,Answer,Good,Good,,No,Very Well,Yes,Yes,Yes,No,"I think for future outreach, it would be cool if videos of the tutorials be posted on YouTube along with the tutorials on github. That way the course could reach more people and allow others to repeat lessons easily.",Video,,5,"deep sequencing. Probably there are many unknown taxa or taxa not available in a database. If the taxonomy is not a concern this wouldn't be a problem, but if it is maybe building your own database could be helpful.","Amplicon sequencing using miseq would be enough for taxonomic information, but this would not provide functional identification. In order to have that a metagenomics approach would be necessary.",Answer,Answer,Very Good,Very Good,,No,Very Well,Yes,Yes,Yes,No,"I believe that more in depth lectures covering each topic (as the one for amplicon sequencing) before the computational part would make easier to understand and assimilate the content of the topics. The lectures given by TAs were good, but some of them were not as polished as the ones given by the main instructors. I think that doing a mock presentation beforehand among all of you would improve their lectures.Thank you very much everyone!",Ordering,,6,"Sequence multiple replicates, paired-end 251x251 V4 of 16S. Will use FastQC to evaluate quality, mothur to cluster and annotate. Distance matrix from mothur with metadata in R to establish correlations.","9 replicates from each experimental treatment. Khmer and trimmomatic and MetaG to clean up and get the DNA ready for assembly, megahit to assemble. Data still might miss rare members or genes, but less likely with 9 replicates. Functional genes of interest can be discovered within the data by local BLAST.",Answer,Answer,Very Good,Very Good,QIIME answer is not meaningful as I didn't take that part of the workshop. ,No,Very Well,Yes,Yes,Yes,No,"More work with amplicons and R would have been helpful, say on Friday. Instructors were all very helpful, especially Tracy working one-on-one with individuals at the end of the first week.",Morework,,7,I would expect to face issues relating to annotation and aligning with a reference database since this type of enviroment is unique and likely harbours a unique community. So I would perform deeper reads on each sample at the expense of reducing sample number because I want to get more resolution of the individuals in each sample. I would also curate my own reference database because it would save alot of time instead of blasting it against everything. It would be good to have the database of a similar enviroment so I would know what type of bacteria to include. ,"I would calculate richness, evenness, and diversity indices between each soil type. I would then compare the two sample types to each other by doing pcoa , dissimilarity , and clustering analysis. I could also do a correlation analysis to see if the diversity difference between the two sample was due to environmental factors (distance, P and N levels, etc). The community in the dair cow pasture is likely very different than the one in the corn growing soil. Perhaps I would consider using MG-RAST.  ",Answer,Answer,Good,Very Good,,No,Very Well,Yes,Yes,Yes,No,"I would have liked some more clarification on the chronological order of putting raw sequences through a workflow. Towards the end of the course, I become confused on the order of the tutorial. Maybe this will be cleared up more during the concept map session. ",Morework,,8,"I would obviously isolate the microbes and extract their DNA. I would sequence the V4 region and use mothur to check and align the genes. Since the worm has a unique digestive tract, it possible that at least some of OTUs present would not map to a reference database. Thus, I'd try to use an open reference form of clustering to match up the sequences that do have a good reference and use de novo clustering to cluster the remaining, unmatched sequences. I'd analyze the output using the vegan package in R.","Depends on your question! If I was looking at functional differences in the soil, perhaps in nitrogen cycling, I would assemble the metagenomes into contigs and annotate them to get an idea of the presence of the various components of the nitrogen cycle. If I was looking at more rare metabolic pathway, I might use Xander to specifically assembly around my gene of interest. The sensitivity of the sequencing is dependent on how many samples you put in each run. Genes and functions that are more common are more likely to show up.",Answer,Answer,Very Good,Very Good,"Wow! Not too often that you get to see Pat, Jim, and Rich all at the same workshop, not to mention all the other fantastic speakers we had! ",No,Very Well,Yes,Yes,Yes,No,"This was a great opportunity for me to learn something that I've been needing to learn for a while! I can't imagine having to learn all this on my own, it would have been much much more difficult. I really appreciate it!One recommendation that I do have for the tutorials is running through the programs and the scripts first, THEN having us work through the tutorials on our own. I think this would do a better job of giving us an overview of what the program is doing and what it is capable of, rather than focusing on properly copying and pasting the code. Then we would be able to work through it more at our own pace. This is advantageous for those who have seen the programs before, since they can get all the overview at the beginning that they may not fully understand, then go ahead or help others, rather than having to wait at each step to see if there's any new information for them. It would also be helpful for those who have never seen the program to be able to focus just on what the program is doing, and not on completing the code.You've put together a really good group of teachers, and the class is just the right size to facilitate familiarity and intimacy while still having a diverse crowd. Thanks so much!",Suggestion,,9,"I would use amplicon 16S sequencing of the V3 region of the rRNA, per Pat Schloss's recommendation. I would use paired end illumina MiSeq to determine the taxonomic constituents of the gut microbiome. Using mothur I would process the raw sequence data, and then output an OTU table. I would export this OTU table into R, and create distance matrices that I would then use to determine the alpha and beta diversity (between worms). I would run a series of statistical analyses to answer given questions. I would expect to be challenged by the resolution of the reference databases in regards to how I can assign accurate taxonomy to the OTU's. ","The analysis would depend entirely upon the question. If I was studying carbon cycling between the two plots, I would use a paired amplicon and shotgun approach to assess taxonomic composition of fungi and bacteria and the genes that are present in the respective soils. For fungi and bacteria I would use seperate primers to amplify 28 S and 16S regions of the genome. After assessing the taxonomic composition of the respective communities, I would look to see what sorts of genes would make sense to be observed in a metagenomic analysis. Metagenomically speaking I would use FunGene as a reference library for my desired genes of interest that I would curate and bin against. I would also take contextual data for each plot and do enzyme analyses of the soil to determine how the genes are likely to be expressed given what I find in each plot. I would look for broad ecological differences, and not concern myself with small significance values given the problems with primer bias, annotation, reference library inadequacy, etc. ",Answer,Answer,Good,Very Good,,No,Very Well,Yes,Yes,Yes,No,It would help me if the various strategies we learned in the workshop were put more explicitly in a research context. Meaning that we started with a hypothesis we wanted to test and then walked through an entire analysis from sequencing on wards using all the different tricks an protocols we learned. That would help me better understand when and why I use shotgun metagenomics and with what other tools we learned about. It would help the ideas 'stick' in my head if I knew exactly in what scenarios I would be using ncbi databases etc. ,Research,,10,Amplicon.  Challenges would be contamination and unmapped organisms.,Depends what the hypothesis is and funding limitations.  I would do 16S to identify who is there and possibly metagenomic.  ,Answer,Answer,Good,Good,"Most invited speaks were very good and complemented the course.  THE HPCC speaker did not provide information in the appropriate context for the students of the course.  As a biologist, I don't need to know how the HPCC is set up, I need to know what parameters I am allowed to use and what a run command looks like for the cluster.",No,Somewhat,Yes,Yes,Yes,No,"Most useful modules where those that the instructors explained what the code was doing and why we were doing it.  Some instructors clicked through their module and then asked ""did you do the command"" and then moved on and repeated without teaching the class what was happening.General workshop suggestions:  Please have the workshop for only a week.  Scheduling several intense days up front followed by 4 half days of instruction is frusterating.",Useful,,11,"I would suggest a targeted amplicon analysis using universal 16S primers.  Miseq could probably be used for sequencing.  Paired-end reads should be taken and, funds allowing, long reads with high overlap should be obtained to allow for cross-checking of specific bases during the merging of paired-end reads.  Challenges during analysis could include artificial inflation of OTU counts due to PCR artifacts, and finding approaching databases for reference based OTU assignment (particularly as the worm is a non-model organism and may include many undescribed bacteria).  Performing the analysis would (likely) require some analysis software, such as Qiime, Mothur, or USEARCH.  Additional computing resources may be required and both Amazon EC2 and high-performance computer clusters may be utilized to resolve this need.","An assembly of the data should be performed. The data should be binned prior to assembly if it is a large dataset as this will allow for processes in lower RAM environments. The assembly should be checked for errors.  Once this assembly is completed raw reads can be aligned against this assembly to obtain read counts.  Identification of specific genes (i.e. functional sequence identification) can be performed in several ways including through annotation, BLAST, and HMMer alignment to a reference database.  Taxanomic sequence identification may be more challenging, but could be performed by using using something like HMMer to search for whole genomes or genes with the potential to allow taxanomic identification (18S, 16S, ITS etc).  That said, if taxanomic identification is the primary goal, amplicon analysis represents a far more efficient approach for determining this.",Answer,Answer,Very Good,Very Good,,No,Very Well,Yes,Yes,Yes,No,"It was all fantastic.  I have no criticisms.  More time to work on, or even discuss, the problems in our own data (and associated analyses) might be nice, but I couldn't make any suggestions as to anything that should be cut to make time for this.  Likewise, a little more theoretical explanation of some of the analyses might be nice, but again, time was limited and used very efficiently.  I thought that basic material and the general schedule were both excellent.  There were just enough breaks and recreational opportunities to maximize learning potential (speaking personally).",Positive,,12,"Collect samples and process to obtain 16s rRNA amplicon sequences. Determine the quality of the amplicon reads obtained and filter out non-useful data. Make a OTU table with selected sequences, align and assign taxonomy using a database (downloaded or constructed). Proceed with Alpha and Beta analysis for diversity and multivariate analysis.","You can try shotgun sequencing analysis to obtain a lot of data but the specificity will be limited. The sequencing data can be assembled, or processed for selection of marker genes or cluster (to reduce the size of query). Assembly helps to identify new organisms but with a lot of genomic redundance and read-based approaches can help to identify functional genes.",Answer,Answer,Very Good,Very Good,,No,Very Well,Yes,Yes,Yes,No,"HPCC talk could be the first day then followed by introduction to the shell and EC2. Tutorials on how to connect to EC2 should be 1st by demonstrating what needs to get done and then step by step with everyone following along. If possible, might be useful if TA's are assigned to a specific table because I think it will streamline solving issues.",Ordering,,13,"You'd first want to think about controls (mock community, negative controls) and the number of replicates and sequencing depth needed to answer your question...that is also key...you should have a specific question to guide your sequencing efforts. Next you'd want to think about whether you want to target 16S genes only or also do metagenomic sequencing. In terms of challenges: you'd want to try to balance depth with cost and also number of replicates and you'd want to try to think about whether you would like to do referenced based, de novo, or open-ended (combo of ref and de novo) methods for annotating your sequences. You'd also want to think about the type of chemistry and sequencing technology (several people have mentioned issues with V3 chemistry). You'd also want to think about the amount of data you'll generate and if your hpcc or cloud can handle your analysis. In terms of additional resources, you'd want to talk to people that have sequenced things before to double check your calculations and also the hpcc people at your institute to make sure you can analyze it. Also look at the mothur or qiime documentation in order to choose one that would be best for your applications.","First you'd want to think about your research question and whether you are more interested in who's there or what they're doing. If who, they you could do 16S rRNA amplicon analysis, and if what they're doing, you could do shotgun metagenomic analysis. For the amplicon approach you'd want to follow a bioformatics pipeline that's best for you using qiime or mothur and use R to test for statisically differences between the OTUs of the two treatments. For the metagenomic approach you could either assemble reads and map reads to get counts of contigs (in this case these are similar to OTUs) or you could do a target gene approach using a database/repository like FunGene assembly using Xander. Technical limitations would include depth of sequence coverage and limitations of the methods you use (these depend on what you use). ",Answer,Answer,Very Good,Very Good,I attended the mothur workshop and it was great to hear from Pat himself about the differences between mothur and qiime. I think I have a great background understanding of concepts after taking this course and am looking forward to diving into my data. I'm still a little overwhelmed about doing this on my own but at the same time know I have lots of resources and where to find help so if I get stuck.,No,Very Well,Yes,Yes,Yes,No,"Thank you so much for all your hard work and for organizing this workshop! In the beginning I did not realize we would be covering amplicon sequencing analysis but am glad you did this. The metagenomic analysis tutorials were great especially the explanation of some of the harder concepts such as kmer/Blooms filters was really helpful to understanding the whole workflow when I go off and do it on my own. The speakers were all great and inspiring to hear from. It was also great that Pat himself taught the mothur workshop. It would have been cool to have a final group project at the end where we try to answer a hypothesis but we just ran out of time for this and that's ok. The teachers and TAs were energetic, patient, helpful and quickly responded to red stickies. It was really helpful to go through the workflows at the start before diving and again at the end so we could think of the bigger picture approach before (maybe) getting lost in the weeds.In terms of improvements, I mentioned one potential one above. I can't really think of any others. Thanks again!",Positive,,14,"I would do a metagenomic analysis of the 16S. A metagenomic reference database/library will be built using targeted gene assembly specific for the breakdown of the specialized diet. I would then align my 16S sequences to the reference library to identify the non-model worm.problems-  No reference database. ","First, if looking at total DNA from soil samples (focussing on micro-organisms) I would use a suite of primers to amplify both bacterial and fungal dna. For bacteria I would use 16S primers and would amplify the fungal ITS2 region. I would choose these regions because they would offer high resolution at the species taxonomic level. After receiving the sequences back from the core I would process using mother. The Silva database would be used with the bacterial sequences for both alignment and taxonomic identification. The UNITEv6 database will be used for classification and taxonomic identification of the fungal sequences. A Denovo alignment will be used in the fungal pipeline. In the past I have classified to species at 97% similarity but would increase to at least 98% at a minimum. I would compare alpha diversity within each of the sites (corn and cow pasture) and then conduct analyses comparing beta diversity between the two sites. phylogenomic comparisons would be difficult while amplifying the ITS2 region and would move to the LSU amplification if I wanted to construct phylogenies. Also important to note that I believe ~50,000 sequences would be needed per sample with a minimum of 9 soil samples to properly analyze the plots. ",Answer,Answer,Good,Good,,No,Somewhat,Yes,No,Yes,No,"I really enjoyed the course. There are two things that stuck out to me that I would recommend.1) I think for the amplicon analysis people it is really important to have skills in multiple software forms. I was really hoping to have the opportunity to learn both mothur and Qiime. I really didn't like that we had to chose between the two. I am a predominately mothur user, but there are often times when I come to a stop in the road and the advice I get is to run that command or that ""alignment"" (whatever it may be) in Qiime. By coming here I was hoping to sharpen my skills in mothur and explore some new options in Qiime. Considering the amplicon analysis was for the most part just one day I felt this really limited how much I was able to grow on this front. Perhaps making the amplicon analysis days spread out into two days, one being mothur and the other being a Qiime day, the people interested in amplicon analyses would see and more importantly learn about multiple options. I'm coming out of here as much a Qiime newbie as I was a week ago. Very sad.2) I thought there would be more focus on discussing experiments and hypothesis testing. There were several times I was asking myself ""what is this useful for? More importantly, what questions can I answer with these tools?"" I think those discussions should be had before each tutorial. I personally need to know what framework I'm working within otherwise things just feel like a black box for me. It wasn't until I talked with a classmate about their questions on the 3rd day of metagenome assembly that I truly understood how these tools are useful. I suppose I felt a bit like the big picture was skimmed over. Without having or understanding guiding questions the rest falls to the wayside. ",Skills,,15,"Strategy:miSeq of the particular variable region that can best inform me about the diversity of this communitywould need to find out the best sequencing depth for this system. If I consider I need about 25,000 reads for soil samples (more diverse that the gut community) it might be reasonable to use something in between 10,000 and 20,000 sequences for the gut community samples (could test in this sequencing effort was enough by rarefaction curves latter in the downstream sequencing analysis)I would use the de novo OTU picking method in Qiime so I get to pick all the reads in the community. I would explore this method first to find out if the OTUs I am obtaining could be really representing part of the gut community Challenges:Public taxonomic databases might not be representative of this particular gut communityAdditional resources:Expect to find lots of unknown bacteria given the novelty of that community. I would create a subset of unknown and BLAST them so I can find out more information on taxonomic composition ","For taxonomic composition I would assemble the reads I obtained for each soils before taxonomic classification. If case of functional diversity, I would pick up the genes related to the function of my interest (say nifH, nirfA, etc) and look specifically for those genes, since they might not be that abundant in the community.",Answer,Answer,Very Good,Good,,No,Very Well,Yes,Yes,Yes,No,,NoAnswer,,16,"Illumina Miseq platform targetting v4 region will be the best option. Depending on the samples and experiemntal design (if any), # of replicates have to be taken into consideration. we should get paired end reads of 250bp, and the raw reads can be assessed for quality score and processed through pipeline of interest (qiime/mothur).The artifact of sequencing like chimera should be expected, and analyses that showed overwhelmingly high diversity should be analyzed cautiously due to this reason. Additional resources such as database like Silva, RDP can be used to get information on taxonomic classification, and statitical test can be run in programs like R for data visualization, and community comparison. ","Illumina HiSeq can be utilized to generate shotgun metagenomic data to get further information on microbial community and functional genes that might be significant depending on the plot types. In terms of sensitivity, we should expect that some taxa might be more abundances while others might be rare, therefore we have to take into consideration the sequencing depth and the sampling effort to fully capture the diversity. this is also through if we are assessing any particular gene of interest. The analyses have to incorporate diginorm steps, and depending on research objectives, the metagenomic data can be analyzed either through assembly approach to rebuild individua genome or read-mapping approach.",Answer,Answer,Very Good,Very Good,,No,Very Well,Yes,Yes,Yes,No,"Since I am working on amplicon-based sequencing, I know some background knowledge related to the data analyses prior to coming to this workshop (such as research objective, experimental design, database involved in analyses). I look forward to learn more on amplicon-based analyses and to get insight on metagenomic-analyses, and all crew members really did an excellent jobs and meet my expectation:) However, I wish that for metagenomic analyses session, tutorials can be built and tailored with research objectives (using mock samples/community) to help me understand more the whole idea of doing metagenomic. Overall, kudos to all!! Thank you as well for bbq, volleyball.. really enjoy my stay here!",Skills,,17,"I would use MiSeq for the amplicon sequencing (likely V4 region unless there are specific organisms I expect to be important in this system that are missed by those primers). The amount of samples per run would need to be calculated based on sequencer output and expected diversity.  I would then trim the reads and create otu tables using mothur and run the statistics through R to see if there were community differences.... hmmm there's no real control here.  I guess we would look for interesting members that we could extrapolate may be involved in this unique metabolism, particularly if there is information available on strains that are capable of this type of metabolism.  Personally, I would only run this as a 16S analysis if I had an appropriate control to compare to (or a species in mind with these skills) and would instead run this as shotgun and look for metabolic genes of interest in this particular gut community.","My expected sensitivity to gene identification (taxonomic or functional) is going to depend on the depth of sequencing (amount per sample, length of reads, and choice of MiSeq or HiSeq).  I presume for a study of soil by shotgun sequencing I would use HiSeq and maximize the depth per sample.  I would then want to assemble the reads, and to do this I would combine the replicates to have greater coverage and then map the reads from each individual replicate to the contigs to see abundance of those genes in each sample.  I could then pull out all the 16S genes in order to compare the taxonomic diversity at each site (comparing alpha and beta diversity using standard metrics) and I could do PCoA analysis on the functional genes to look for differences between the communities.  I feel the taxonomic analysis would be much more limited if it were done this way since you don't get the depth of sequencing that you can get from an amplicon analysis.  For the functional analysis, the PCoA can indicate whether there are differences between the two sites, but I'm not really sure how to go about identifying the specific genes responsible for those changes (other than pulling out genes that have a particular peak in abundance in one site over the other)",Answer,Answer,Good,Very Good,,No,Very Well,Yes,No,Yes,No,"Overall, the tutorials are awesome and the material covered is very good.  One thing I felt could really be improved was understanding the input and output files.  Since most things were done with demo data, I felt that the students didn't necessarily get a feel for how to wrangle their own files into the appropriate formats or what data to expect out of each program.  I think it would improve the course to specifically discuss the different data formats at the beginning of the course and to have a very clear breakdown in the tutorial of what the input files need to be and what each program is generating.",Skills,,18,"- Sample collection - whole gut samples- Tissue samples from different sections within each gut sample? i.e. small intestine, caecum- Extraction/purification- Library - Ilumina Miseq- 20-25,000 coverageChallenges:- What region do you use? i.e. V4?- Potential for contaminationAdditional resources:- Relevant peer reviewed journals for laboratory protocols and statistical analyses (worth considering in advance)...what coverage did they use? what region? what primers? etc.- For analysis; HPCC or EC2, reference database (e.g. NCBI)","- Receive raw sequencing data from platform (fastq)- Merge paired-end reads- Pick OTUs; quality control/check for chimeras, cluster at 97% identity, pick representative sequences, assign taxonomy to representative sequences, align, make OTU tables- Rarefy to even sampling depth - Visualise differences between corn and dairy pastures using R (.biom output)...bar charts/heat maps/PCoA**Include sanity checks throughout your analysis workflow ",Answer,Answer,Very Good,Very Good,"Please note, I did attend the Mothur classes. ",No,Very Well,Yes,Yes,Yes,No,"TAs/instructors were incredible - I was really impressed with the level of knowledge and their eagerness to help answer questions/fix problems...no matter what time of day! I really can't speak more highly of the TAs...I bet you are super proud!As someone who came in to this knowing very little of how to approach bioinformatics, I now feel I have the knowledge, resources and confidence to do exactly what I need to do...which is a really liberating feeling!We had flash presentations but it would maybe be cool to offer the opportunity for anyone who has their data in more advanced stages (or have completed projects recently) to present their work to the class. Maybe just short, optional 15 min presentations. Travel arrangements for the conference were a little pushed against the wire if travelling from outside the state - same for arrangements to leave. ",Teachers,Beginner,19,"I'd use Illumina paired-end sequencing. -Challenge 1: probably getting a huge number of unidentified OTUs. Since our worm is non-model, there will likely be lots of sequences from species not represented in reference databases.-Challenge 2: merging paired-end reads is not perfect. There will likely be errors that could over-inflate the number of OTUs in my analysis.-Challenge 3: identifying species reliably from 16S sequences can be difficult since this locus evolves very slowly.-Challenge 4: we probably can't learn much about organismal function from 16S sequences, unless we're able to identify the species associated with a given 16S sequence and understand it's function/physiology.Resources: a reference database would be helpful to try to identify OTUs. ","Analysis 1) I could use targeted assembly, looking at nitrogen-cycle-specific genes (for example).Analysis 2) I could use metagenome assembly, looking at ""all"" genes and hopefully being able to properly annotate their functions.For both analyses: I'm guessing expected sensitivity/specificity to taxonomic and functional sequence identification would be fairly good, because I'm sure many studies have looked at agricultural soil samples and inputted the common species they find into public databases.Analysis #1 technical limitations: This is probably not super-high-throughput if I want to look at more than a dozen genes or so.Analysis #2 technical limitations: rare taxa will likely be 'lost' due to lots of reads from super-high abundant taxa. Also, metagenome assembly is not perfect, and neither is binning, so the number of OTUs we come up with may be wrong. Annotation is certainly subject to limitations as well, since many sequences won't match databases, and those that do could be annotated incorrectly if the database isn't curated.",Answer,Answer,Very Good,Good,,No,Very Well,Yes,Yes,Yes,No,"I really enjoyed this course overall, and feel much more comfortable using the command line, running scripts, navigating through the terminal, and preparing to do targeted amplicon and metagenomics analyses!  One thing I particularly liked about the course was the accessibility of the instructors and TAs for questions. I think having such a large number of instructors was extremely helpful and necessary to adequately meet all the questions in a class of 35 students. I am a beginner and had many questions, but every instructor and TA that I spoke to was both patient and knowledgeable.The QIIME tutorial (and the cartoon workflow drawn up by Ashley) was extremely clear and helpful! I feel armed and ready to go with QIIME. Same with R: I like how we worked through an entire data analysis: from inputting data to visualizing PCoAs. I also liked how we were able to work through the complete R script for the paper currently in prep in Ashley's lab. I also really enjoyed when we were assigned ""exercises"": opportunities to apply what we learned in the tutorials, and take it a step further. For example, after we learned the 'head' command, we were challenged to write a script that grabbed the first 10 lines of a file and wrote the output to a new file.  I think more of this would be extremely helpful!I think one thing that could be removed from the course is the guest seminars (the 8pm seminars). I liked the talks, but I thought we might get a bit more out of the course if we used that time doing more computational tutorials, allowing us to cover a bit more information in the course. An alternative would be to possibly condense the 9 days of the workshop into a day or two fewer by working more in the evenings rather than the 8pm talks. I understand it's a tough tradeoff though that everyone might get a bit burnt out if we worked in the evenings too. Just something I was thinking.",Teachers,Skills,Exercises20,"I would check the literature to see what 16S region gives the best results from this environment. I would do the DNA extraction and sequencing in triplicates, and I would analyze the sequencing data in usearch / QIIME. i don't know if its right, but it may be useful to pool the sequences together to obtain an accurate picture of the community. I could be helpful to download other 16S libraries from close related organisms (NCBI, SRA) and to analyze what changes in community structure had occur in this worm's gut. A would explore the alpha and beta diversity using the vegan package in R. I would make some statistical (like Kruskal-Wallis) tests to see what OTUs have significant different abundances in this worm gut comparing to other guts.","Because these are soil samples I would choose an HiSeq approach in order to obtain a good sequencing depth. First I would trim the raw sequencing data, I would normalize it, and than I would assemble the reads into contigs. I would assign the taxonomy and I would try to see if there are differences between the two sample sites. Next, if I am interested in particular elements cycle (N, P etc) I would try to investigate the functional diversity. I would make databases (db) for the targeted genes (from NCBI) and I would blast my contigs over those db to see that genes are present. To obtain the gene abundances I would map my reads over my contigs and I would use the abundances to get the gene abundances - because in the blast report we can see in which contig the genes were found. We can do same statistics and see how these sampling sites differ from one another, but because we analyze the DNA, not ARN or proteins, we don't know to what extent are results an accurate representation of the functional capabilities.",Answer,Answer,Good,Very Good,,No,Very Well,Yes,Yes,Yes,No,,NoAnswer,,21,"The sequencing strategy would encompass 16S rRNA amplicon sequencing analysis for sequencing using the Illumina MiSeq.  You would like want to use 6-9 replicates of the worm depending on the variability of the worm gut microbiome (could look at previous studies to see how many replicates were needed).  Then you would need to decide which variable region of the 16S to sequence and what Illumina chemistry to use for library prep (likely 250 PE v2 chemistry of the V4 region is optimal). The challenges will be how much sequencing depth you will need to sample the community and what ecological questions you are asking (will you be treating the worms with different diets, etc.).  Resources are the computing power to analyze, such as the Amazon EC2 cloud instance or your institutional HPC, software tools for analysis (QIIME, mothur) and statistical tools (R).  Data hygiene and a computing workflow (for others to check and reproduce your work) are key!  Overall, you need to check quality with fastqc, merge your reads (pandaseq, usearch, or qiime), if there was not quality filtering step then quality filter in usearch or qiime, and then go on to otu picking/clustering, assigning taxonomy, diversity analyses (within and between sample diversity) and then input these to QIIME.  Make sure samples have even sampling depth before doing the multivariate statistics.  ","For this study, you would want to run as least duplicate or triplicate biological samples for each plot type so you could account for variability.  The first step is to determine what sequencing type you need (Illumina HiSeq) and how many lanes.  An Illumina run is 1Tbp with 8 lanes per run so you will need to decide how many lanes to run.  Considering the diversity of soil you might only want to run 1 or 2 of the samples per lane of HiSeq Illumina.  Next you will need you have a computing resource (enough RAM and processors) to process the data and expect that it will take a while. Also make sure to save the raw data  in a folder that will remain untouched and that there is a backup of the data.  The first step is to trim off the adaptors (trimmomatic), check quality (fastx), digital normalization (using kmers), filtering errors and redundancies, run the assembly (megahit - kmers), evaluate the assembly (quast), then estimating the abundances by mapping the raw reads back to the assembly (bowtie).  The annotation can be done through MG-RAST or Blast or other programs (prodigal, blast contigs to uniref or other database).  The assembly can also be binned to reduce complexity using metabat. The sensitivity will depend on the diversity of your sample and how much sequencing depth you obtained.  The specificity of the analysis depends on the assembly and databases used.  The assembly is a technical limitation depending on how many kmers you use and how conserved different gene regions are.  This can also take a long time to run.  ",Answer,Answer,Very Good,Very Good,,No,Very Well,Yes,Yes,Yes,No,"-more work through R -run throughs on both qiime and mothur (I did mothur, but I wanted to see how instructors use qiime)-have the amazon EC2 credits approved way ahead of the workshop and explain pricing of both instances and volumes-have students read through next day's tutorials the night before-more exercises running automation and writing more in depth scripts-have students design a computing workflow for their own data",Suggestions,,22,"Not sure why I would be a doing a 16S marker analysis for this project.  Why not an analysis focused on genes related to breakdown of the specialized elements of this diet? This would be possible if there are relevant microbial genes already identified - a database of such genes would be a helpful resource.  I would consider doing a shotgun analysis instead of an amplicon analysis and then probe for specific genes of interest. This might cost more, so monetary resources would also be important.","Still not liking this experimental set up.  Need to look at these plot types on more than one farm, or the ability to draw conclusions about cause and effect is severely limited.",Answer,Answer,Very Good,Very Good,,No,Somewhat,,Yes,Yes,No,,NoAnswer,,23,"I would first decide what region of the 16S would give me more information on diversity and select the primers accordingly. This is challenging because I would expect to obtain novel sequences. I would do technical replicates and include also a mock community sample to account for sequencing artifacts. After quality control, I would assemble paired-end reads and define OTUs and assign taxonomy using an ""open reference"" approach because I expect to obtain novel OTUs. I would remove singletons, do explorative diversity and analyze within-sample diversity.Resources: uclust, QIIME or mothur for amplicon analysis, GeneFun database to assign taxons, and R for diversity analysis and plots.","I would expect that the microbial communities are different. Metagenome analysis is based on massive data consisting in short reads that include a lot of errors. I would then sequence to have a coverage of 50x for each site. I would do quality check and trimming to remove adapters, digital normalization and remove low coverage reads to improve data quality. Then I would assemble the metagenomes and evaluate them. I would then do reference mapping to assess abundances of reads and quantify gene presence for each of the sites. I would annotate taxonomy and function of metagenomes and evaluate the differences between the two soil farm types.",Answer,Answer,Very Good,Very Good,,No,Very Well,Yes,Yes,Yes,No,"I have learned so much, I really have no complaints. Although I need some time to process all the information, most of all regarding metagenome analysis.",Positive,,24,,,NoAnswer,NoAnswer,Very Good,Very Good,,No,Very Well,Yes,Yes,Yes,No,,,,25,,,NoAnswer,NoAnswer,Good,Good,,Yes,Very Well,Yes,Yes,Yes,Yes,,,,